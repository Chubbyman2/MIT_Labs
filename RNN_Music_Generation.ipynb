{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIT Lab 1.2 - RNN Music Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chubbyman2/MIT_Labs/blob/master/RNN_Music_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXebNNtQJbwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "!pip install mitdeeplearning\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "import numpy as np\n",
        "import os \n",
        "import time\n",
        "import functools\n",
        "from IPython import display as ipythondisplay\n",
        "from tqdm import tqdm\n",
        "!apt-get install abcmidi timidity > /dev/null 2>&1\n",
        "\n",
        "assert len(tf.config.list_physical_devices(\"GPU\")) > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P66YibY5jxKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "songs = mdl.lab1.load_training_data()\n",
        "\n",
        "# Print one song, inspect in greater detail\n",
        "example_song = songs[0]\n",
        "print(\"\\nExample song: \")\n",
        "print(example_song)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocWKTuALkrMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the ABC notation to audio file\n",
        "mdl.lab1.play_song(example_song)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xjTO-HGk4Lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Join list of song strings into a single string containing all the songs\n",
        "songs_joined = \"\\n\\n\".join(songs)\n",
        "\n",
        "# Find all unique characters in the joined string\n",
        "vocab = sorted(set(songs_joined))\n",
        "print(\"There are\", len(vocab), \"unique characters in the dataset.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ3biyHWlVRz",
        "colab_type": "text"
      },
      "source": [
        "**Vectorize the Text**\n",
        "\n",
        "Two tables:\n",
        "\n",
        "1. Maps characters to numbers\n",
        "\n",
        "2. Maps numbers back to characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdo9RN2_lL8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# e.g. Index of character \"d\" is char2idx[\"d\"]\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "\n",
        "idx2char = np.array(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXbNrWMulyLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"{\")\n",
        "for char,_ in zip(char2idx, range(20)):\n",
        "  print(\" {:4s}: {:3d},\".format(repr(char), char2idx[char]))\n",
        "print(\" ...\\n}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKhzaQD9mQbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_string(string):\n",
        "  vectorized_output = np.array([char2idx[char] for char in string])\n",
        "  return vectorized_output\n",
        "\n",
        "vectorized_songs = vectorize_string(songs_joined)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdrIYCZgnuI2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ('{} ---- characters mapped to int ----> {}'.format(repr(songs_joined[:10]), vectorized_songs[:10]))\n",
        "# check that vectorized_songs is a numpy array\n",
        "assert isinstance(vectorized_songs, np.ndarray), \"returned result should be a numpy array\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTjpHoehodyD",
        "colab_type": "text"
      },
      "source": [
        "**Create training examples and targets**\n",
        "\n",
        "Text will break into chunks of seq_length+1.\n",
        "\n",
        "i.e. seq_length = 4 and text is \"Hello\", input sequence is \"Hell\" and target sequence is \"ello\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LkPiGEFoXvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batch(vectorized_songs, seq_length, batch_size):\n",
        "  # the length of the vectorized songs string\n",
        "  n = vectorized_songs.shape[0] - 1\n",
        "  # randomly choose the starting indices for the examples in the training batch\n",
        "  idx = np.random.choice(n-seq_length, batch_size)\n",
        "\n",
        "  '''TODO: construct a list of input sequences for the training batch'''\n",
        "  input_batch = [vectorized_songs[i : i+seq_length] for i in idx]\n",
        "  # input_batch = # TODO\n",
        "  '''TODO: construct a list of output sequences for the training batch'''\n",
        "  output_batch = [vectorized_songs[i+1 : i+seq_length+1] for i in idx]\n",
        "  # output_batch = # TODO\n",
        "\n",
        "  # x_batch, y_batch provide the true inputs and targets for network training\n",
        "  x_batch = np.reshape(input_batch, [batch_size, seq_length])\n",
        "  y_batch = np.reshape(output_batch, [batch_size, seq_length])\n",
        "  return x_batch, y_batch\n",
        "\n",
        "\n",
        "# Perform some simple tests to make sure your batch function is working properly! \n",
        "test_args = (vectorized_songs, 10, 2)\n",
        "if not mdl.lab1.test_batch_func_types(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_shapes(get_batch, test_args) or \\\n",
        "   not mdl.lab1.test_batch_func_next_step(get_batch, test_args): \n",
        "   print(\"======\\n[FAIL] could not pass tests\")\n",
        "else: \n",
        "   print(\"======\\n[PASS] passed all tests!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bc-C3IXqDvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_batch, y_batch = get_batch(vectorized_songs, seq_length=5, batch_size=1)\n",
        "\n",
        "for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):\n",
        "    print(\"Step {:3d}\".format(i))\n",
        "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
        "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjXs4_mWqXI5",
        "colab_type": "text"
      },
      "source": [
        "**The RNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcvVHEC6qIBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTM(rnn_units):\n",
        "  return tf.keras.layers.LSTM(\n",
        "      rnn_units,\n",
        "      return_sequences=True,\n",
        "      recurrent_initializer=\"glorot_uniform\",\n",
        "      recurrent_activation=\"sigmoid\",\n",
        "      stateful=True\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVaONjcGqnCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "    # Transforms indices into dense vectors of a fixed embedding size                           \n",
        "    tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "    \n",
        "    # Call the LSTM function\n",
        "    LSTM(rnn_units),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "# Give default hyperparameters\n",
        "model = build_model(len(vocab), embedding_dim=256, rnn_units=1024, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxePlNZDrkdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j33a8bdgrpY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = get_batch(vectorized_songs, seq_length=100, batch_size=32)\n",
        "pred = model(x)\n",
        "print(\"Input shape: \", x.shape, \"# (batch_size, sequence_length)\")\n",
        "print(\"Prediction shape: \", pred.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHAR6e9vtNqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sampled_indices = tf.random.categorical(pred[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I56UmX28tdg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[x[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m0C7yvMuCgc",
        "colab_type": "text"
      },
      "source": [
        "**Training the Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSSHnSqzt1--",
        "colab_type": "text"
      },
      "source": [
        "Now we need to train the model so the prediction isn't a bunch of mumbo jumbo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeUt4243t7DS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss(labels, logits):\n",
        "  loss = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "  return loss\n",
        "\n",
        "example_batch_loss = compute_loss(y, pred)\n",
        "\n",
        "print(\"Prediction shape: \", pred.shape, \" # (batch_size, sequence_length, vocab_size)\") \n",
        "print(\"scalar_loss: \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjCB1buMu2V0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimization Parameters\n",
        "num_training_iterations = 2000\n",
        "batch_size = 4\n",
        "seq_length = 100\n",
        "learning_rate = 5e-3\n",
        "\n",
        "# Model parameters\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "# Checkpoint Location\n",
        "checkpoint_dir = \"./training_checkpoints\"\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"my_ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gS2lucDvegd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    # Feed input into model and generate predictions\n",
        "    y_hat = model(x)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = compute_loss(y, y_hat)\n",
        "\n",
        "  # Compute gradients\n",
        "    # Hint: Use `model.trainable_variables` to get a list of all model parameters\n",
        "  grads = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "  # Apply gradients to the optimizer so it can update the model accordingly\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "  return loss\n",
        "\n",
        "# Begin training\n",
        "\n",
        "history = []\n",
        "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel=\"Iterations\", ylabel=\"Loss\")\n",
        "if hasattr(tqdm, \"_instances\"): tqdm._instances.clear() # Clear if it exists\n",
        "\n",
        "for iter in tqdm(range(num_training_iterations)):\n",
        "\n",
        "  # Grab a batch and propagate it through the network\n",
        "  x_batch, y_batch = get_batch(vectorized_songs, seq_length, batch_size)\n",
        "  loss = train_step(x_batch, y_batch)\n",
        "\n",
        "  # Update progress bar\n",
        "  history.append(loss.numpy().mean())\n",
        "  plotter.plot(history)\n",
        "  \n",
        "  # Update model with changed weights\n",
        "  if iter % 100 == 0:\n",
        "    model.save_weights(checkpoint_prefix)\n",
        "\n",
        "# Save trained model and weights\n",
        "model.save_weights(checkpoint_prefix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO_91XDYnsZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "# Restore model weights for the last checkpoint after training\n",
        "  # This is required when you change the batch_size\n",
        "\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvBZZhj3oJyV",
        "colab_type": "text"
      },
      "source": [
        "**The Prediction Procedure**\n",
        "\n",
        "Initialize a \"seed\" start string and the RNN state, and set the number of characters we want to generate.\n",
        "\n",
        "Use the start string and the RNN state to obtain the probability distribution over the next predicted character.\n",
        "\n",
        "Sample from multinomial distribution to calculate the index of the predicted character. This predicted character is then used as the next input to the model.\n",
        "\n",
        "At each time step, the updated RNN state is fed back into the model, so that it now has more context in making the next prediction. After predicting the next character, the updated RNN states are again fed back into the model, which is how it learns sequence dependencies in the data, as it gets more information from the previous predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUNdDjpMo1OC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string, generation_length=1000):\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  text_generated = []\n",
        "\n",
        "  model.reset_states()\n",
        "  tqdm._instances.clear()\n",
        "\n",
        "  for i in tqdm(range(generation_length)):\n",
        "    predictions = model(input_eval)\n",
        "    \n",
        "    # Remove batch dimension\n",
        "    predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "    # Pass prediction and previous hidden state as inputs to the model\n",
        "    input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + \"\".join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fU_AIQDpppv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_text = generate_text(model, start_string=\"X\", generation_length=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8RMDVyhpwco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generated_songs = mdl.lab1.extract_song_snippet(generated_text)\n",
        "\n",
        "for i, song in enumerate(generated_songs):\n",
        "  waveform = mdl.lab1.play_song(song)\n",
        "\n",
        "  # If the song is valid, play it\n",
        "  if waveform:\n",
        "    print(\"Generated song\", i)\n",
        "    ipythondisplay.display(waveform)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}